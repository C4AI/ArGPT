{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kJr_Rreqk-mP"},"outputs":[],"source":["# Install necessary packages\n","! pip install datasets\n","! pip install -U accelerate\n","! pip install -U transformers\n","! pip install seqeval\n","! pip install evaluate\n","! pip install pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36330,"status":"ok","timestamp":1686749972392,"user":{"displayName":"Victor Hugo Nascimento Rocha","userId":"02623097946324066115"},"user_tz":180},"id":"69BpP31jX5gC","outputId":"2258954f-4089-4546-e533-5a8d360809db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","# Path to dataset files\n","path = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yc3uY36FvTmo"},"outputs":[],"source":["import pandas as pd\n","\n","# Span\n","file_path = path + \"/argument_span.csv\"\n","df_span = pd.read_csv(file_path, header=0)\n","df_span = df_span[[\"text_id\", \"tokens\", \"chunk_tags\", \"split\"]]\n","df_span[\"tokens\"] = df_span.tokens.apply(lambda x: x[1:-1].split(', '))\n","df_span[\"tokens\"] = df_span[\"tokens\"].apply(lambda x: [i.replace(\"'\", \"\").strip() for i in x])\n","df_span[\"chunk_tags\"] = df_span.chunk_tags.apply(lambda x: x[1:-1].split(','))\n","df_span[\"chunk_tags\"] = df_span[\"chunk_tags\"].apply(lambda x: [int(i, 32) for i in x])\n","df_span_train = df_span[df_span[\"split\"] == \"TRAIN\"]\n","df_span_test = df_span[df_span[\"split\"] == \"TEST\"]\n","df_span_val = df_span[df_span[\"split\"] == \"VAL\"]\n","df_span_train = df_span_train.drop(columns=[\"split\"], axis=1)\n","df_span_test = df_span_test.drop(columns=[\"split\"], axis=1)\n","df_span_val = df_span_val.drop(columns=[\"split\"], axis=1)\n","df_span_train = df_span_train.reset_index(drop=True)\n","df_span_test = df_span_test.reset_index(drop=True)\n","df_span_val = df_span_val.reset_index(drop=True)\n","\n","# Relations\n","file_path = path + \"/argument_relations.csv\"\n","df_relation = pd.read_csv(file_path, header=0)\n","df_relation = df_relation[[\"text_id\", \"source_tokens\", \"target_tokens\", \"labels\", \"split\"]]\n","df_relation[\"labels\"] = df_relation[\"labels\"].replace(\"support\", 0)\n","df_relation[\"labels\"] = df_relation[\"labels\"].replace(\"attack\", 1)\n","df_relation[\"labels\"] = df_relation[\"labels\"].replace(\"None\", 2)\n","df_relation_train = df_relation[df_relation[\"split\"] == \"TRAIN\"]\n","df_relation_test = df_relation[df_relation[\"split\"] == \"TEST\"]\n","df_relation_val = df_relation[df_relation[\"split\"] == \"VAL\"]\n","df_relation_train = df_relation_train.drop(columns=[\"split\"], axis=1)\n","df_relation_test = df_relation_test.drop(columns=[\"split\"], axis=1)\n","df_relation_val = df_relation_val.drop(columns=[\"split\"], axis=1)\n","df_relation_train = df_relation_train.reset_index(drop=True)\n","df_relation_test = df_relation_test.reset_index(drop=True)\n","df_relation_val = df_relation_val.reset_index(drop=True)\n","\n","# Evaluations\n","file_path = path + \"/text_evaluations.csv\"\n","df_evaluation = pd.read_csv(file_path, header=0)\n","df_evaluation = df_evaluation[[\"text_id\", \"tokens\", \"final_grade\", \"split\"]]\n","df_evaluation[\"final_grade\"] = df_evaluation[\"final_grade\"].apply(lambda x: float(x))\n","df_evaluation_train = df_evaluation[df_evaluation[\"split\"] == \"TRAIN\"]\n","df_evaluation_test = df_evaluation[df_evaluation[\"split\"] == \"TEST\"]\n","df_evaluation_val = df_evaluation[df_evaluation[\"split\"] == \"VAL\"]\n","df_evaluation_train = df_evaluation_train.drop(columns=[\"split\"], axis=1)\n","df_evaluation_test = df_evaluation_test.drop(columns=[\"split\"], axis=1)\n","df_evaluation_val = df_evaluation_val.drop(columns=[\"split\"], axis=1)\n","df_evaluation_train = df_evaluation_train.reset_index(drop=True)\n","df_evaluation_test = df_evaluation_test.reset_index(drop=True)\n","df_evaluation_val = df_evaluation_val.reset_index(drop=True)\n","\n","# Component\n","df_texts = df_evaluation[[\"text_id\", \"tokens\"]]\n","file_path = path + \"/argument_components.csv\"\n","df_component = pd.read_csv(file_path, header=0)\n","df_component = df_component[[\"text_id\", \"component_tokens\", \"labels\", \"split\"]]\n","df_component = df_component.merge(df_texts, how=\"left\", on=\"text_id\")\n","df_component.rename(columns={\"tokens\": \"text_tokens\"}, inplace=True)\n","df_component[\"labels\"] = df_component[\"labels\"].replace(\"MajorClaim\", 0)\n","df_component[\"labels\"] = df_component[\"labels\"].replace(\"Premise\", 1)\n","df_component_train = df_component[df_component[\"split\"] == \"TRAIN\"]\n","df_component_test = df_component[df_component[\"split\"] == \"TEST\"]\n","df_component_val = df_component[df_component[\"split\"] == \"VAL\"]\n","df_component_train = df_component_train.drop(columns=[\"split\"], axis=1)\n","df_component_test = df_component_test.drop(columns=[\"split\"], axis=1)\n","df_component_val = df_component_val.drop(columns=[\"split\"], axis=1)\n","df_component_train = df_component_train.reset_index(drop=True)\n","df_component_test = df_component_test.reset_index(drop=True)\n","df_component_val = df_component_val.reset_index(drop=True)\n","\n","# Argument Quality\n","file_path = path + \"/argument_quality.csv\"\n","df_argument_quality = pd.read_csv(file_path, header=0)\n","df_argument_quality = df_argument_quality.drop(columns=[\"Unnamed: 0\"], axis=1)\n","df_argument_quality_train = df_argument_quality[df_argument_quality[\"split\"] == \"TRAIN\"]\n","df_argument_quality_test = df_argument_quality[df_argument_quality[\"split\"] == \"TEST\"]\n","df_argument_quality_val = df_argument_quality[df_argument_quality[\"split\"] == \"VAL\"]\n","df_argument_quality_train = df_argument_quality_train.drop(columns=[\"split\"], axis=1)\n","df_argument_quality_test = df_argument_quality_test.drop(columns=[\"split\"], axis=1)\n","df_argument_quality_val = df_argument_quality_val.drop(columns=[\"split\"], axis=1)\n","df_argument_quality_train = df_argument_quality_train.reset_index(drop=True)\n","df_argument_quality_test = df_argument_quality_test.reset_index(drop=True)\n","df_argument_quality_val = df_argument_quality_val.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2bb59da5b6bc4f62a722bf413a822ac7","e9ef6110260d4e9a8fce2d2a4ad6505d","265346198bfc4efc9f54ce7dc5b535de","0aed780844ab4a0face47f081e2943ce","ce09ca7d6ce8434eaadf78beede6e6cb","409a10caec2941a79acaf005b6153d9f","5038670bce854ac69bb0d57768a5771f","753f7a9fa41d4766b057ab1d8b1f4f29","de1d29c15e2141d0af03696802f0c790","f571fceb9d1447598e5997e867d301e8","9874dc194b664d2fbeb89b9586fc0374"]},"executionInfo":{"elapsed":17524,"status":"ok","timestamp":1686749996480,"user":{"displayName":"Victor Hugo Nascimento Rocha","userId":"02623097946324066115"},"user_tz":180},"id":"_76oIDumAfny","outputId":"556202de-028a-4c46-c8ee-4891217638cd"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bb59da5b6bc4f62a722bf413a822ac7","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import evaluate\n","import datasets\n","from datasets import Dataset, DatasetDict, Features\n","from datasets import load_dataset, load_metric\n","\n","metric = evaluate.load(\"seqeval\")"]},{"cell_type":"markdown","metadata":{"id":"etMsAwUcyyd1"},"source":["# **Span Detection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkTkVhng01-U"},"outputs":[],"source":["# Create Dataset I for span detection\n","\n","features = Features(\n","    (\n","      {\n","          \"text_id\": datasets.Value(\"int32\"),\n","          \"tokens\": datasets.Sequence(datasets.Value(\"string\")),\n","          \"chunk_tags\":datasets.Sequence(\n","              datasets.features.ClassLabel(\n","                  names=[\n","                      \"O\",\n","                      \"B-ARG\",\n","                      \"I-ARG\",\n","                  ]\n","              )\n","          )\n","      }\n","        )\n","  )\n","\n","train_ds = Dataset.from_pandas(df_span_train, features=features)\n","test_ds = Dataset.from_pandas(df_span_test, features=features)\n","val_ds = Dataset.from_pandas(df_span_val, features=features)\n","original_data_span = DatasetDict()\n","original_data_span[\"train\"] = train_ds\n","original_data_span[\"test\"] = test_ds\n","original_data_span[\"eval\"] = val_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWVgnht7eVig"},"outputs":[],"source":["task_feature = original_data_span[\"train\"].features[\"chunk_tags\"]\n","label_names = task_feature.feature.names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4036,"status":"ok","timestamp":1686758870414,"user":{"displayName":"Victor Hugo Nascimento Rocha","userId":"02623097946324066115"},"user_tz":180},"id":"JONabvzdglWO","outputId":"cef1f45b-ab14-4650-8edf-a248dc9ca2c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["id2label = {i: label for i, label in enumerate(label_names)}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","model_checkpoint = \"roberta-base\"\n","#model_checkpoint = \"bert-base-cased\"\n","\n","from transformers import (\n","    AutoModelForTokenClassification, AutoTokenizer,\n","    )\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n","\n","model =  AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    id2label=id2label,\n","    label2id=label2id,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJ_KTzCiygkR"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }\n","\n","\n","def align_labels_with_tokens(labels, word_ids):\n","    new_labels = []\n","    current_word = None\n","    for word_id in word_ids:\n","        if word_id != current_word:\n","            # Start of a new word!\n","            current_word = word_id\n","            label = -100 if word_id is None else labels[word_id]\n","            new_labels.append(label)\n","        elif word_id is None:\n","            # Special token\n","            new_labels.append(-100)\n","        else:\n","            # Same word as previous token\n","            label = labels[word_id]\n","            # If the label is B-XXX we change it to I-XXX\n","            if label % 2 == 1:\n","                label += 1\n","            new_labels.append(label)\n","\n","    return new_labels\n","\n","\n","def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[\"tokens\"], is_split_into_words=True, truncation=True,\n","    )\n","    all_labels = examples[\"chunk_tags\"]\n","    new_labels = []\n","    for i, labels in enumerate(all_labels):\n","        word_ids = tokenized_inputs.word_ids(i)\n","        new_labels.append(align_labels_with_tokens(labels, word_ids))\n","\n","    tokenized_inputs[\"labels\"] = new_labels\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73sDYRKu7SSr"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n","\n","labels = original_data_span[\"train\"][0][\"chunk_tags\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["c025af3feb0f49d9831a5b81323dc8a9","8d462009d5d0471e9ca4ab33977b6061","6171e222c39c4e26ab116f5354ec4697","31b3c2a09b63439199202b39b1853f0b","fc0d6d32b55c458b9b7091b324996751","ff35e9c536764e03831b92d67d25b824","335dcd2753e74852b848cf3b6c09d3a0","a373b0ba674b49e29dcd864f627f94d0","8f5a57c4c145450c9c2ca18dce697f7b","17f0a48f06f34002b253584e67e3a010","e0a1a6d2811144eb8a40e8f2ba3ca24f","205f59e72a5f43c3966d0b16d186cd62","80f96a9b0d3043f7bee394ba784cd613","358292f984694c99b493de006de6a6ad","c13b8ad0dbbd4898bad795649834bedc","b8bae8fff8bd4c77a7c8d5265233c856","080c8cf0a7f74257a0259ac09f332fb3","6b42f8816e7c43d2af4a25fa28037ed4","8556f4bb3a784ca486c88ac38812aa67","f5b925ae9cc84a8782e8124acc377914","8c75845715184a568347ec0de1380807","47f62d0564f04443a744b23d4f4d9518","c6d1dc98e1624feb947859045f22ac02","3435d76c418744f19d11ab63c74437ea","2cd540a93f7542b29bbb400db57e17e7","234e6dfad40946b3b7f2dd899910234d","c3e91be7cc7441699f7f3f237bc7286b","3590eda43b024c02b4f102d38d44c389","eb1828eb3aed42ff9ce064850a6d9efd","9228bf40d7dd4fa3a1627c6926f338c6","4188f77145ee4b83bd3c6d8ce84e0052","183119527a214769b525609afd0d53e6","713db3b1c98c45e791fdca17469d5643"]},"executionInfo":{"elapsed":1109,"status":"ok","timestamp":1686758878382,"user":{"displayName":"Victor Hugo Nascimento Rocha","userId":"02623097946324066115"},"user_tz":180},"id":"swp7j454evXc","outputId":"626bfa47-5fb4-419e-cdd4-8b77e2ca09b4"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c025af3feb0f49d9831a5b81323dc8a9","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/135 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"205f59e72a5f43c3966d0b16d186cd62","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/16 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6d1dc98e1624feb947859045f22ac02","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/17 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_training_input = original_data_span.map(\n","    tokenize_and_align_labels,\n","    batched=True,\n","    remove_columns=original_data_span[\"train\"].column_names,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfvHoTwaXQoD"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","filepath = path + \"\"\n","\n","args = TrainingArguments(\n","    output_dir=filepath,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=15,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    seed=42,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_training_input[\"train\"],\n","    eval_dataset=tokenized_training_input[\"eval\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2IcntNFY34L"},"outputs":[],"source":["# Train pre-trained model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkXqqSB3Ir0_"},"outputs":[],"source":["# Make prediction\n","trainer.evaluate(tokenized_training_input[\"test\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1686759503638,"user":{"displayName":"Victor Hugo Nascimento Rocha","userId":"02623097946324066115"},"user_tz":180},"id":"ffa-sHurDI_i","outputId":"6879a25b-aff5-45ab-96e0-e219a3386dd4"},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["predictions = trainer.predict(tokenized_training_input[\"test\"])\n","pred = np.argmax(predictions.predictions, axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"dCgPu13ZF3q6"},"source":["Generate Evaluation Metrics (Recreate the components to evaluate the performance)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2BHVDZbt-7S"},"outputs":[],"source":["true_components = list()\n","for_test = list()\n","total = 0\n","for i, labels in enumerate(list(tokenized_training_input[\"test\"])):\n","  labels_list = [elem for elem in list(labels[\"labels\"]) if elem != -100]\n","  text_len = len(labels_list)\n","  former_label = 0\n","  start = -1\n","  end = -1\n","  for j, label in enumerate(labels_list):\n","    if label == 1 and former_label == 0:\n","      start = j\n","    elif label == 1 and former_label in (1,2):\n","      end = j-1\n","      component = [i, start, end]\n","      true_components.append(str(component))\n","      start = j\n","      end = -1\n","    elif label == 0 and former_label in (1,2):\n","      end = j-1\n","      component = [i, start, end]\n","      true_components.append(str(component))\n","      start = -1\n","      end = -1\n","    elif j+1 == text_len and start != -1:\n","      end = j\n","      component = [i, start, end]\n","      true_components.append(str(component))\n","      start = -1\n","      end = -1\n","    elif label == 2:\n","      continue\n","    former_label = label\n","  if start != -1 and end == -1:\n","    print(f\"ERROR: {i}\")\n","    print(labels_list)\n","    end = text_len - 1\n","    component = [i, start, end]\n","    true_components.append(str(component))\n","\n","  text_components = len(true_components) - total\n","  for_test.append(text_components)\n","  total = len(true_components)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"No1NURhMpwz8"},"outputs":[],"source":["predicted_components = list()\n","for i, labels in enumerate(list(pred)):\n","  labels_list = [elem for elem in list(labels) if elem != -100]\n","  labels_list.pop(0)\n","  former_label = 0\n","  start = -1\n","  end = -1\n","  for j, label in enumerate(labels_list):\n","    if label == 1 and former_label == 0:\n","      start = j\n","    elif label == 1 and former_label in (1,2):\n","      end = j-1\n","      component = [i, start, end]\n","      predicted_components.append(str(component))\n","      start = j\n","      end = -1\n","    elif label == 0 and former_label in (1,2):\n","      end = j-1\n","      component = [i, start, end]\n","      predicted_components.append(str(component))\n","      start = -1\n","      end = -1\n","    elif label == labels_list[-1] and start != -1:\n","      end = j\n","      component = [i, start, end]\n","      predicted_components.append(str(component))\n","      start = -1\n","      end = -1\n","    former_label = label\n","  if start != -1 and end == -1:\n","    print(f\"ERRO: teste {i}\")\n","    end = text_len - 1\n","    component = [i, start, end]\n","    predicted_components.append(str(component))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UW9gYL5WQzIl"},"outputs":[],"source":["def intersection(lst1, lst2):\n","  return list(set(lst1) & set(lst2))\n","\n","# Not considering truncation\n","correct_answers = intersection(true_components, predicted_components)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWiFE1bSB3Di"},"outputs":[],"source":["import re\n","# Restore Components (To TEST THE CODE)\n","list_of_true_components = list()\n","\n","for true_component in true_components:\n","\n","  # Extract the elements of the list from the string\n","  elements = re.findall(r'\\d+', true_component)\n","\n","  # Convert the elements to integers\n","  res = [int(x) for x in elements]\n","\n","  # Get text\n","  text_num, start, end = res\n","  text = tokenized_training_input[\"test\"][\"input_ids\"][text_num]\n","  component = list()\n","  for i in range(start+1, end+2):\n","    component.append(text[i])\n","  decoded_component = tokenizer.decode(component, skip_special_tokens= True).strip()\n","  decoded_component = re.sub(r'[^\\w]', ' ', decoded_component).replace(\" \", \"\")\n","  list_of_true_components.append(decoded_component)\n","\n","df_corrected = df_component_test[[\"component_tokens\", \"text_id\"]]\n","#df_span[\"tokens\"] = df_span.tokens.apply(lambda x: x[1:-1].split(', '))\n","df_corrected['component_tokens'] = df_corrected.component_tokens.apply(lambda x:re.sub(r'[^\\w]', ' ', x).strip().replace(\" \", \"\"))\n","\n","df_correct = df_corrected[df_corrected[\"component_tokens\"].isin(list_of_true_components)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHNuj7MdwGuf"},"outputs":[],"source":["# Restore components from predicted answer\n","\n","list_of_predicted_components = list()\n","\n","for predicted_component in predicted_components:\n","\n","  if predicted_component in correct_answers:\n","    continue\n","\n","  # Extract the elements of the list from the string\n","  elements = re.findall(r'\\d+', predicted_component)\n","\n","  # Convert the elements to integers\n","  res = [int(x) for x in elements]\n","\n","  # Get text\n","  text_num, start, end = res\n","  text_id = df_span_test.iloc[text_num][\"text_id\"]\n","  text_tokens = df_texts[df_texts[\"text_id\"] == text_id].iloc[0][\"tokens\"]\n","\n","  text = tokenized_training_input[\"test\"][\"input_ids\"][text_num]\n","  component = list()\n","  for i in range(start+1, end+1):\n","    component.append(text[i])\n","  decoded_component = tokenizer.decode(component, skip_special_tokens= True).strip()\n","  list_of_predicted_components.append({\n","      \"text_id\": text_id,\n","      \"component_tokens\": decoded_component,\n","      \"labels\": \"premise\",\n","      \"text_tokens\": text_tokens\n","  })\n","\n","print(len(list_of_predicted_components))\n","df_wrongly_predicted_components = pd.DataFrame(list_of_predicted_components, columns = [\"text_id\", \"component_tokens\", \"labels\", \"text_tokens\"])\n","\n","relations_data = list()\n","\n","for component in list_of_predicted_components:\n","  text_id = component[\"text_id\"]\n","  source_text = component[\"component_tokens\"]\n","  for target_component in list_of_predicted_components:\n","    if source_text == target_component[\"component_tokens\"] or text_id != target_component[\"text_id\"]:\n","      continue\n","    else:\n","      target_text = target_component[\"component_tokens\"]\n","      relation_data = dict()\n","      relation_data[\"text_id\"] = text_id\n","      relation_data[\"source_tokens\"] = source_text\n","      relation_data[\"target_tokens\"] = target_text\n","      relation_data[\"labels\"] = \"None\"\n","      relations_data.append(relation_data)\n","\n","df_wrongly_predicted_relations = pd.DataFrame(relations_data, columns = relations_data[0].keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mR_LKHR-B7cm"},"outputs":[],"source":["# Restore Components from correct answers\n","list_of_correct_components = list()\n","\n","for correct_component in correct_answers:\n","\n","  # Extract the elements of the list from the string\n","  elements = re.findall(r'\\d+', correct_component)\n","\n","  # Convert the elements to integers\n","  res = [int(x) for x in elements]\n","\n","  # Get text\n","  text_num, start, end = res\n","  text = tokenized_training_input[\"test\"][\"input_ids\"][text_num]\n","  component = list()\n","  for i in range(start+1, end+2):\n","    component.append(text[i])\n","  decoded_component = tokenizer.decode(component, skip_special_tokens= True).strip()\n","  decoded_component = re.sub(r'[^\\w]', ' ', decoded_component).replace(\" \", \"\").strip()\n","  list_of_correct_components.append(decoded_component)\n","\n","# Get component test dataframe, but only with the components indeed correctly found\n","\n","df_corrected = df_component_test.copy()\n","df_corrected['component_tokens'] = df_corrected.component_tokens.apply(lambda x:re.sub(r'[^\\w]', ' ', x).strip().replace(\" \", \"\"))\n","\n","df_corrected = df_corrected[df_corrected[\"component_tokens\"].isin(list_of_correct_components)]\n","print(df_corrected.shape)\n","\n","#print(list(set(list_of_correct_components) - set(df_corrected[\"component_tokens\"].to_list())))\n","\n","index_list = df_corrected.index.values.tolist()\n","df_component_test_corrected = df_component_test.iloc[index_list]\n","df_component_test_corrected = df_component_test_corrected.reset_index(drop=True)\n","\n","# Get relations test dataframe, but only with the components indeed correctly found\n","df_corrected = df_relation_test.copy()\n","df_corrected[\"source_tokens\"] = df_corrected.source_tokens.apply(lambda x:re.sub(r'[^\\w]', ' ', x).strip().replace(\" \", \"\"))\n","df_corrected[\"target_tokens\"] = df_corrected.target_tokens.apply(lambda x:re.sub(r'[^\\w]', ' ', x).strip().replace(\" \", \"\"))\n","\n","df_corrected = df_corrected[df_corrected[\"source_tokens\"].isin(list_of_correct_components)]\n","df_corrected = df_corrected[df_corrected[\"target_tokens\"].isin(list_of_correct_components)]\n","\n","index_list = df_corrected.index.values.tolist()\n","df_relationt_test_corrected = df_relation_test.iloc[index_list]\n","df_relationt_test_corrected = df_relationt_test_corrected.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXECWxQX21wU"},"outputs":[],"source":["# Properly considers truncation\n","inter = df_component_test_corrected.shape[0]\n","\n","precision = len(predicted_components) and inter/len(predicted_components) or 0\n","recall = len(true_components) and inter/len(true_components) or 0\n","f1 = precision and recall and (2*precision*recall)/(precision+recall) or 0\n","\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1-score: {f1}\")"]},{"cell_type":"markdown","metadata":{"id":"IqwI6RU7p7yD"},"source":["# **Component Classification**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIuZ-pbtItPS"},"outputs":[],"source":["# Create Dataset II for component classificantion\n","features = Features(\n","    (\n","      {\n","          \"text_id\": datasets.Value(\"int32\"),\n","          \"component_tokens\": datasets.Value(\"string\"),\n","          \"labels\": datasets.features.ClassLabel(\n","                  names=[\n","                      \"major claim\",\n","                      \"premise\",\n","                  ]\n","              ),\n","          \"text_tokens\": datasets.Value(\"string\"),\n","      }\n","        )\n","  )\n","train_ds = Dataset.from_pandas(df_component_train, features=features)\n","test_ds = Dataset.from_pandas(df_component_test, features=features)\n","corrected_test_ds = Dataset.from_pandas(df_component_test_corrected, features=features)\n","predicted_test_ds =  Dataset.from_pandas(df_wrongly_predicted_components, features=features)\n","val_ds = Dataset.from_pandas(df_component_val, features=features)\n","original_data_component = DatasetDict()\n","original_data_component[\"train\"] = train_ds\n","original_data_component[\"test\"] = test_ds\n","original_data_component[\"eval\"] = val_ds\n","original_data_component[\"corrected_test\"] = corrected_test_ds\n","original_data_component[\"predicted_test\"] = predicted_test_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-OaXru3Pnos"},"outputs":[],"source":["task_feature = original_data_component[\"train\"].features[\"labels\"]\n","label_names = task_feature.names\n","id2label = {i: label for i, label in enumerate(label_names)}\n","label2id = {v: k for k, v in id2label.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-f4DXaqPfv-"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForSequenceClassification,\n","     DataCollatorWithPadding\n","    )\n","\n","model_checkpoint = \"roberta-base\"\n","#model_checkpoint = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n","\n","model_component = AutoModelForSequenceClassification.from_pretrained(\n","  model_checkpoint, id2label=id2label, label2id=label2id,\n",")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQIHC9ffw0ec"},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"component_tokens\"], examples[\"text_tokens\"], padding=True, truncation=\"only_second\")\n","\n","tokenized_training_input = original_data_component.map(preprocess_function, batched=True, remove_columns=[\"component_tokens\", \"text_tokens\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ta5guF2tB-Sg"},"outputs":[],"source":["from torch import nn\n","import torch\n","from transformers import Trainer\n","\n","\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        # compute custom loss (suppose one has 3 labels with different weights)\n","        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([9.0, 1.0]).to(\"cuda\"))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvLbtlP5t3gk"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import numpy as np\n","import pandas as pd\n","from transformers import TrainingArguments, Trainer\n","\n","\n","def compute_metrics_component(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    precision = precision_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    f1_macro = f1_score(average=\"macro\", y_true=labels, y_pred=pred )\n","    f1 = f1_score(average=\"micro\", y_true=labels, y_pred=pred )\n","    f1_weighted = f1_score(average=\"weighted\", y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}\n","\n","\n","filepath = path + \"\"\n","\n","component_args = TrainingArguments(\n","    output_dir=filepath,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=15,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    seed=42,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_macro\",\n","    greater_is_better=True\n",")\n","component_trainer = CustomTrainer(\n","    model=model_component,\n","    args=component_args,\n","    train_dataset=tokenized_training_input[\"train\"],\n","    eval_dataset=tokenized_training_input[\"eval\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_component,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLplq9QqyjXP"},"outputs":[],"source":["# Train pre-trained model\n","component_trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5hfDtW0ylUC"},"outputs":[],"source":["# Make predictions\n","component_trainer.evaluate(tokenized_training_input[\"test\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wcw7V1ZHtW-z"},"outputs":[],"source":["# Corrected metrics\n","corrected_prediction = component_trainer.evaluate(tokenized_training_input[\"corrected_test\"])\n","acc = corrected_prediction[\"eval_accuracy\"]\n","num_correct_components_final = int(acc*inter)\n","\n","precision = len(predicted_components) and num_correct_components_final/len(predicted_components) or 0\n","recall = len(true_components) and num_correct_components_final/len(true_components) or 0\n","f1 = precision and recall and (2*precision*recall)/(precision+recall) or 0\n","\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1-score: {f1}\")\n","\n","# Corrected F1 Macro\n","sum = 0\n","predictions = component_trainer.predict(tokenized_training_input[\"predicted_test\"])\n","pred = np.argmax(predictions.predictions, axis=-1)\n","labels = [\"major claim\", \"premise\"]\n","\n","for label in [0, 1]:\n","  corrected_label_prediction = component_trainer.evaluate(tokenized_training_input[\"corrected_test\"].filter(lambda example: example[\"labels\"] == label))\n","  print(corrected_label_prediction)\n","  label_acc = corrected_label_prediction[\"eval_accuracy\"]\n","\n","  num_corrected_label = df_component_test_corrected[df_component_test_corrected[\"labels\"] == labels[label]].shape[0]\n","  num_correct_components = int(label_acc*num_corrected_label)\n","  num_test_label = df_component_test[df_component_test[\"labels\"] == labels[label]].shape[0]\n","  num_predicted_label = list(pred).count(label)\n","\n","  precision = num_corrected_label and num_correct_components/(num_predicted_label+num_correct_components) or 0\n","  recall = num_test_label and num_correct_components/num_test_label or 0\n","  f1_macro = precision and recall and (2*precision*recall)/(precision+recall) or 0\n","  print(num_correct_components)\n","\n","\n","  sum = sum + f1_macro\n","\n","macro = sum/2\n","\n","print(f\"F1-score Macro: {macro}\")"]},{"cell_type":"markdown","metadata":{"id":"iPrd3aTY5szG"},"source":["# **Relation Classification**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmgP--F_BEZD"},"outputs":[],"source":["# Create Dataset III for relation classificantion\n","features = Features(\n","    (\n","      {\n","          \"text_id\": datasets.Value(\"int32\"),\n","          \"source_tokens\": datasets.Value(\"string\"),\n","          \"target_tokens\": datasets.Value(\"string\"),\n","          \"labels\": datasets.features.ClassLabel(\n","                  names=[\n","                      \"support\",\n","                      \"attack\",\n","                      \"None\"\n","                  ]\n","              )\n","      }\n","        )\n","  )\n","train_ds = Dataset.from_pandas(df_relation_train, features=features)\n","test_ds = Dataset.from_pandas(df_relation_test, features=features)\n","corrected_test_ds = Dataset.from_pandas(df_relationt_test_corrected, features=features)\n","predicted_test_ds = Dataset.from_pandas(df_wrongly_predicted_relations, features=features)\n","val_ds = Dataset.from_pandas(df_relation_val, features=features)\n","original_data_relation = DatasetDict()\n","original_data_relation[\"train\"] = train_ds\n","original_data_relation[\"test\"] = test_ds\n","original_data_relation[\"eval\"] = val_ds\n","original_data_relation[\"corrected_test\"] = corrected_test_ds\n","original_data_relation[\"predicted_test\"] = predicted_test_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8SwQOLj5u1g"},"outputs":[],"source":["task_feature = original_data_relation[\"train\"].features[\"labels\"]\n","label_names = task_feature.names\n","id2label = {i: label for i, label in enumerate(label_names)}\n","label2id = {v: k for k, v in id2label.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Aw8Y-ou6EsK"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForSequenceClassification,\n","     DataCollatorWithPadding\n","    )\n","\n","model_checkpoint = \"roberta-base\"\n","#model_checkpoint = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n","\n","model_relation = AutoModelForSequenceClassification.from_pretrained(\n","  model_checkpoint, id2label=id2label, label2id=label2id,\n",")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMKSsoIU6M6r"},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"source_tokens\"], examples[\"target_tokens\"], padding=True, truncation=True)\n","\n","tokenized_training_input = original_data_relation.map(preprocess_function, batched=True, remove_columns=[\"source_tokens\", \"target_tokens\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuPKF2NZRQwf"},"outputs":[],"source":["from torch import nn\n","import torch\n","from transformers import Trainer\n","\n","\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        # compute custom loss (suppose one has 3 labels with different weights)\n","        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([2.0, 1.0, 0.06]).to(\"cuda\"))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jaw6LhEK6nfR"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import numpy as np\n","import pandas as pd\n","from transformers import TrainingArguments, Trainer\n","\n","\n","def compute_metrics_relations(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    precision = precision_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    f1 = f1_score(average=\"micro\", y_true=labels, y_pred=pred)\n","    f1_macro = f1_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    f1_weighted = f1_score(average=\"weighted\", y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}\n","\n","filepath = path + \"\"\n","\n","relation_args = TrainingArguments(\n","    output_dir=filepath,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=15,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    seed=42,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_macro\",\n","    greater_is_better=True,\n",")\n","relation_trainer = CustomTrainer(\n","    model=model_relation,\n","    args=relation_args,\n","    train_dataset=tokenized_training_input[\"train\"],\n","    eval_dataset=tokenized_training_input[\"eval\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_relations,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d1TRtQvS7SMg"},"outputs":[],"source":["# Train pre-trained model\n","relation_trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7IksFvS7cZI"},"outputs":[],"source":["# Make prediction\n","relation_trainer.evaluate(tokenized_training_input[\"test\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJQImQ3zVq9e"},"outputs":[],"source":["## Corrected metrics\n","from itertools import combinations\n","\n","num_possible_correct_relations = df_relationt_test_corrected.shape[0]\n","num_relations = df_relation_test.shape[0]\n","\n","# Duas vezes combinacao de total de componentes previstos para cada grafo 2 a 2\n","components_per_text = dict()\n","for predicted_component in predicted_components:\n","  # Extract the elements of the list from the string\n","  elements = re.findall(r\"\\d+\", predicted_component)\n","\n","  # Get text\n","  text_num, start, end = elements\n","\n","  # Components per text\n","  if not components_per_text.get(text_num, False):\n","    components_per_text[text_num] = 1\n","  else:\n","    components_per_text[text_num] += 1\n","\n","total_predicted_relations = 0\n","for key in components_per_text.keys():\n","\n","  num_component_per_graph = components_per_text[key]\n","  list_evaluation_modules = list(range(1,num_component_per_graph+1,1))\n","  comb = combinations(list_evaluation_modules, 2)\n","  total_predicted_relations += 2*len(list(comb))\n","\n","corrected_prediction = relation_trainer.evaluate(tokenized_training_input[\"corrected_test\"])\n","acc = corrected_prediction[\"eval_accuracy\"]\n","num_correct_relations = int(acc*num_possible_correct_relations)\n","\n","precision = total_predicted_relations and num_correct_relations/total_predicted_relations or 0\n","recall = num_relations and num_correct_relations/num_relations or 0\n","f1 = precision and recall and (2*precision*recall)/(precision+recall) or 0\n","\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1-score: {f1}\")\n","\n","# Corrected F1 Macro\n","sum = 0\n","predictions = relation_trainer.predict(tokenized_training_input[\"predicted_test\"])\n","pred = np.argmax(predictions.predictions, axis=-1)\n","\n","for label in [0, 1, 2]:\n","  corrected_label_prediction = relation_trainer.evaluate(tokenized_training_input[\"corrected_test\"].filter(lambda example: example[\"labels\"] == label))\n","  label_acc = corrected_label_prediction[\"eval_accuracy\"]\n","\n","  num_test_label = df_relation_test[df_relation_test[\"labels\"] == label].shape[0]\n","  num_corrected_label = df_relationt_test_corrected[df_relationt_test_corrected[\"labels\"] == label].shape[0]\n","  num_correct_relations = int(label_acc*num_corrected_label)\n","  num_predicted_label = list(pred).count(label)\n","\n","  precision = num_corrected_label and num_correct_relations/(num_correct_relations+num_predicted_label) or 0\n","  recall = num_test_label and num_correct_relations/num_test_label or 0\n","  f1_macro = precision and recall and (2*precision*recall)/(precision+recall) or 0\n","  sum = sum + f1_macro\n","\n","macro = sum/3\n","\n","print(f\"F1-score Macro: {macro}\")"]},{"cell_type":"markdown","metadata":{"id":"UMYaDz8M6iVo"},"source":["# **Text Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JgqVVu8BLm3"},"outputs":[],"source":["# Create Dataset IV for text evaluation\n","features = Features(\n","    (\n","      {\n","          \"text_id\": datasets.Value(\"int32\"),\n","          \"tokens\": datasets.Value(\"string\"),\n","          \"final_grade\": datasets.Value(\"float32\")\n","      }\n","        )\n","  )\n","train_ds = Dataset.from_pandas(df_evaluation_train, features=features)\n","test_ds = Dataset.from_pandas(df_evaluation_test, features=features)\n","val_ds = Dataset.from_pandas(df_evaluation_val, features=features)\n","original_data_evaluation = DatasetDict()\n","original_data_evaluation[\"train\"] = train_ds\n","original_data_evaluation[\"test\"] = test_ds\n","original_data_evaluation[\"eval\"] = val_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZIZK8RN6cXC"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n","from torch.utils.data import DataLoader\n","\n","model_checkpoint = \"roberta-base\"\n","#model_checkpoint = \"bert-base-cased\"\n","LEARNING_RATE = 2e-5\n","MAX_LENGTH = 512\n","BATCH_SIZE = 8\n","EPOCHS = 15\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R32WNHsr_lXb"},"outputs":[],"source":["# ds = {\"train\": raw_train_ds, \"validation\": raw_val_ds, \"test\": raw_test_ds}\n","\n","def preprocess_function(examples):\n","    label = examples[\"final_grade\"]\n","    examples = tokenizer(examples[\"tokens\"], truncation=True, padding=\"max_length\", max_length=512\n","                         )\n","\n","    # Change this to real number\n","    examples[\"label\"] = float(label)\n","    return examples\n","\n","tokenized_training_input = original_data_evaluation.map(preprocess_function, remove_columns=[\"text_id\", \"tokens\", \"final_grade\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlyNz_czApec"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import cohen_kappa_score\n","import numpy as np\n","\n","def compute_metrics_for_regression(eval_pred):\n","    logits, labels = eval_pred\n","    labels = labels.reshape(-1, 1)\n","    qwk_logits = 100*logits\n","    qwk_labels = 100*labels\n","    qwk_logits = qwk_logits.astype(int)\n","    qwk_labels = qwk_labels.astype(int)\n","\n","    mse = mean_squared_error(labels, logits)\n","    qwk = cohen_kappa_score(qwk_labels, qwk_logits, weights=\"quadratic\")\n","\n","    return {\"mse\": mse, \"qwk\": qwk}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2hhlDagAtBS"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","filepath = path + \"\"\n","\n","evaluation_training_args = TrainingArguments(\n","    output_dir=filepath,\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    metric_for_best_model=\"qwk\",\n","    load_best_model_at_end=True,\n","    weight_decay=0.01,\n","    greater_is_better=True,\n","    seed=42\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=evaluation_training_args,\n","    train_dataset=tokenized_training_input[\"train\"],\n","    eval_dataset=tokenized_training_input[\"eval\"],\n","    compute_metrics=compute_metrics_for_regression\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ospzROT_Bke2"},"outputs":[],"source":["trainer.eval_dataset = tokenized_training_input[\"test\"]\n","trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"HmHgNEK20yf4"},"source":["# **Argument Quality**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrpqBUfE07u0"},"outputs":[],"source":["# Create Dataset V for argument quality evaluation\n","features = Features(\n","    (\n","      {\n","          \"text_id\": datasets.Value(\"int32\"),\n","          \"tokens\": datasets.Value(\"string\"),\n","          \"arg_quality\": datasets.features.ClassLabel(\n","                  names=[\n","                      \"good\",\n","                      \"bad\",\n","                      \"ugly\"\n","                  ]\n","              )\n","      }\n","        )\n","  )\n","train_ds = Dataset.from_pandas(df_argument_quality_train, features=features)\n","test_ds = Dataset.from_pandas(df_argument_quality_test, features=features)\n","val_ds = Dataset.from_pandas(df_argument_quality_val, features=features)\n","original_data_argument = DatasetDict()\n","original_data_argument[\"train\"] = train_ds\n","original_data_argument[\"test\"] = test_ds\n","original_data_argument[\"eval\"] = val_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJqXx79G2EBu"},"outputs":[],"source":["task_feature = original_data_argument[\"train\"].features[\"arg_quality\"]\n","label_names = task_feature.names\n","id2label = {i: label for i, label in enumerate(label_names)}\n","label2id = {v: k for k, v in id2label.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y80_jVqv4wqk"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForSequenceClassification,\n","     DataCollatorWithPadding\n","    )\n","\n","#model_checkpoint = \"roberta-base\"\n","model_checkpoint = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n","\n","model_arg_quality = AutoModelForSequenceClassification.from_pretrained(\n","  model_checkpoint, id2label=id2label, label2id=label2id,\n",")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCf9kFlZ5CG7"},"outputs":[],"source":["def preprocess_function(examples):\n","    label = examples[\"arg_quality\"]\n","    examples = tokenizer(\n","        examples[\"tokens\"], truncation=True, padding=True,\n","    )\n","    examples[\"label\"] = label\n","    return examples\n","\n","tokenized_training_input = original_data_argument.map(preprocess_function, batched=True, remove_columns=[\"text_id\", \"tokens\", \"arg_quality\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9h3QHLU6kDE"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import numpy as np\n","import pandas as pd\n","from transformers import TrainingArguments, Trainer\n","\n","\n","def compute_metrics_quality(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    precision = precision_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    f1 = f1_score(average=\"micro\", y_true=labels, y_pred=pred)\n","    f1_macro = f1_score(average=\"macro\", y_true=labels, y_pred=pred)\n","    f1_weighted = f1_score(average=\"weighted\", y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}\n","\n","filepath = path + \"/Modelos/Revisao/Quality_Task/Bert_Quality\"\n","\n","quality_args = TrainingArguments(\n","    output_dir=filepath,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=15,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    seed=42,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_macro\",\n","    greater_is_better=True\n",")\n","quality_trainer = Trainer(\n","    model=model_arg_quality,\n","    args=quality_args,\n","    train_dataset=tokenized_training_input[\"train\"],\n","    eval_dataset=tokenized_training_input[\"eval\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_quality,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foH7u-iP66ma"},"outputs":[],"source":["# Train pre-trained model\n","quality_trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzEbK2pO7CG3"},"outputs":[],"source":["# Make prediction\n","quality_trainer.evaluate(tokenized_training_input[\"test\"])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"080c8cf0a7f74257a0259ac09f332fb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aed780844ab4a0face47f081e2943ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f571fceb9d1447598e5997e867d301e8","placeholder":"","style":"IPY_MODEL_9874dc194b664d2fbeb89b9586fc0374","value":" 6.34k/6.34k [00:00&lt;00:00, 219kB/s]"}},"17f0a48f06f34002b253584e67e3a010":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"183119527a214769b525609afd0d53e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"205f59e72a5f43c3966d0b16d186cd62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80f96a9b0d3043f7bee394ba784cd613","IPY_MODEL_358292f984694c99b493de006de6a6ad","IPY_MODEL_c13b8ad0dbbd4898bad795649834bedc"],"layout":"IPY_MODEL_b8bae8fff8bd4c77a7c8d5265233c856"}},"234e6dfad40946b3b7f2dd899910234d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_183119527a214769b525609afd0d53e6","placeholder":"","style":"IPY_MODEL_713db3b1c98c45e791fdca17469d5643","value":" 17/17 [00:00&lt;00:00, 160.69 examples/s]"}},"265346198bfc4efc9f54ce7dc5b535de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_753f7a9fa41d4766b057ab1d8b1f4f29","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de1d29c15e2141d0af03696802f0c790","value":6338}},"2bb59da5b6bc4f62a722bf413a822ac7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9ef6110260d4e9a8fce2d2a4ad6505d","IPY_MODEL_265346198bfc4efc9f54ce7dc5b535de","IPY_MODEL_0aed780844ab4a0face47f081e2943ce"],"layout":"IPY_MODEL_ce09ca7d6ce8434eaadf78beede6e6cb"}},"2cd540a93f7542b29bbb400db57e17e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9228bf40d7dd4fa3a1627c6926f338c6","max":17,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4188f77145ee4b83bd3c6d8ce84e0052","value":17}},"31b3c2a09b63439199202b39b1853f0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17f0a48f06f34002b253584e67e3a010","placeholder":"","style":"IPY_MODEL_e0a1a6d2811144eb8a40e8f2ba3ca24f","value":" 135/135 [00:00&lt;00:00, 225.36 examples/s]"}},"335dcd2753e74852b848cf3b6c09d3a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3435d76c418744f19d11ab63c74437ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3590eda43b024c02b4f102d38d44c389","placeholder":"","style":"IPY_MODEL_eb1828eb3aed42ff9ce064850a6d9efd","value":"Map: 100%"}},"358292f984694c99b493de006de6a6ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8556f4bb3a784ca486c88ac38812aa67","max":16,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5b925ae9cc84a8782e8124acc377914","value":16}},"3590eda43b024c02b4f102d38d44c389":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"409a10caec2941a79acaf005b6153d9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4188f77145ee4b83bd3c6d8ce84e0052":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47f62d0564f04443a744b23d4f4d9518":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5038670bce854ac69bb0d57768a5771f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6171e222c39c4e26ab116f5354ec4697":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a373b0ba674b49e29dcd864f627f94d0","max":135,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f5a57c4c145450c9c2ca18dce697f7b","value":135}},"6b42f8816e7c43d2af4a25fa28037ed4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"713db3b1c98c45e791fdca17469d5643":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"753f7a9fa41d4766b057ab1d8b1f4f29":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f96a9b0d3043f7bee394ba784cd613":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_080c8cf0a7f74257a0259ac09f332fb3","placeholder":"","style":"IPY_MODEL_6b42f8816e7c43d2af4a25fa28037ed4","value":"Map:   0%"}},"8556f4bb3a784ca486c88ac38812aa67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c75845715184a568347ec0de1380807":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d462009d5d0471e9ca4ab33977b6061":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff35e9c536764e03831b92d67d25b824","placeholder":"","style":"IPY_MODEL_335dcd2753e74852b848cf3b6c09d3a0","value":"Map: 100%"}},"8f5a57c4c145450c9c2ca18dce697f7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9228bf40d7dd4fa3a1627c6926f338c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9874dc194b664d2fbeb89b9586fc0374":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a373b0ba674b49e29dcd864f627f94d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8bae8fff8bd4c77a7c8d5265233c856":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c025af3feb0f49d9831a5b81323dc8a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d462009d5d0471e9ca4ab33977b6061","IPY_MODEL_6171e222c39c4e26ab116f5354ec4697","IPY_MODEL_31b3c2a09b63439199202b39b1853f0b"],"layout":"IPY_MODEL_fc0d6d32b55c458b9b7091b324996751"}},"c13b8ad0dbbd4898bad795649834bedc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c75845715184a568347ec0de1380807","placeholder":"","style":"IPY_MODEL_47f62d0564f04443a744b23d4f4d9518","value":" 0/16 [00:00&lt;?, ? examples/s]"}},"c3e91be7cc7441699f7f3f237bc7286b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c6d1dc98e1624feb947859045f22ac02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3435d76c418744f19d11ab63c74437ea","IPY_MODEL_2cd540a93f7542b29bbb400db57e17e7","IPY_MODEL_234e6dfad40946b3b7f2dd899910234d"],"layout":"IPY_MODEL_c3e91be7cc7441699f7f3f237bc7286b"}},"ce09ca7d6ce8434eaadf78beede6e6cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1d29c15e2141d0af03696802f0c790":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0a1a6d2811144eb8a40e8f2ba3ca24f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9ef6110260d4e9a8fce2d2a4ad6505d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_409a10caec2941a79acaf005b6153d9f","placeholder":"","style":"IPY_MODEL_5038670bce854ac69bb0d57768a5771f","value":"Downloading builder script: 100%"}},"eb1828eb3aed42ff9ce064850a6d9efd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f571fceb9d1447598e5997e867d301e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b925ae9cc84a8782e8124acc377914":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc0d6d32b55c458b9b7091b324996751":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ff35e9c536764e03831b92d67d25b824":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}